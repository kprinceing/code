{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import jieba\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Embedding,Dropout,Activation,Softmax,Flatten,Conv1D, SimpleRNN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理申请数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 申请数据\n",
    "apps = pd.read_excel(\"/Users/yansong/Nutstore Files/基金研究/data/2013--2022面青/2020.xlsx\",sheet_name = \"申请\")\n",
    "apps.drop(columns=['Unnamed: 0','Unnamed: 2','Unnamed: 5', 'Unnamed: 6','Unnamed: 7', 'Unnamed: 8','项目名称2','姓名','申请单位'],inplace=True)\n",
    "apps_comments = apps[\"反馈评议意见\"].str.split(\"<\", expand = True)\n",
    "df_app = pd.merge(apps, apps_comments, left_index=True, right_index=True)\n",
    "df_app.drop(columns=0,inplace=True)\n",
    "df_app.rename(columns={1: \"意见1\",2: \"意见2\",3: \"意见3\",4: \"意见4\",5: \"意见5\",6: \"意见6\"},inplace=True)\n",
    "df_app.drop(columns=\"反馈评议意见\",inplace=True)\n",
    "\n",
    "# 立项数据\n",
    "grants = pd.read_excel(\"/Users/yansong/Nutstore Files/基金研究/data/2013--2022面青/2020.xlsx\",sheet_name = \"立项\")\n",
    "grants_comments = grants[\"反馈评议意见\"].str.split(\"<\", expand = True)\n",
    "grants_comments.drop(columns=0,inplace=True)\n",
    "grants_comments.rename(columns={1: \"意见1\",2: \"意见2\",3: \"意见3\",4: \"意见4\",5: \"意见5\"},inplace=True)\n",
    "df_grants = pd.merge(grants, grants_comments, left_index=True, right_index=True)\n",
    "df_grants.drop(columns=\"反馈评议意见\",inplace=True)\n",
    "\n",
    "# 计算是否立项\n",
    "def check_grant(a):\n",
    "    return df_grants[\"项目名称\"].isin([a]).sum()\n",
    "df_app[\"立项\"] = df_app[\"项目名称\"].apply(check_grant)\n",
    "\n",
    "df_app.head()\n",
    "df_app = df_app[df_app['资助类别']=='面上项目']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "资助类别\n",
       "面上项目    0.229133\n",
       "Name: 立项, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app.groupby(['资助类别'])[\"立项\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 意见处理\n",
    "{\n",
    "\t\"1\": {\n",
    "\t\t\"id\": \"1\",\n",
    "\t\t\"records\": {\n",
    "\t\t\t\"情感\": [\n",
    "\t\t\t\t\"正\"\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "\t\t\"content\": \"这本书不错啊\"\n",
    "\t},\n",
    "\t\"2\": {\n",
    "\t\t\"id\": \"2\",\n",
    "\t\t\"records\": {\n",
    "\t\t\t\"情感\": [\n",
    "\t\t\t\t\"负\"\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "\t\t\"content\": \"这个东西评价不行\"\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>项目名称</th>\n",
       "      <th>申请人</th>\n",
       "      <th>申请部门</th>\n",
       "      <th>资助类别</th>\n",
       "      <th>意见1</th>\n",
       "      <th>意见2</th>\n",
       "      <th>意见3</th>\n",
       "      <th>意见4</th>\n",
       "      <th>意见5</th>\n",
       "      <th>立项</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>自守形式和自守L-函数的相关解析问题</td>\n",
       "      <td>徐钊</td>\n",
       "      <td>数学学院</td>\n",
       "      <td>面上项目</td>\n",
       "      <td>1&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>2&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>3&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>4&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>5&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>有界格上聚合与推理算子的理论与应用</td>\n",
       "      <td>刘华文</td>\n",
       "      <td>数学学院</td>\n",
       "      <td>面上项目</td>\n",
       "      <td>1&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>2&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>3&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>4&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>5&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>多凯勒参数卡拉比-丘型的纽Gromov-Witten不变量</td>\n",
       "      <td>王新</td>\n",
       "      <td>数学学院</td>\n",
       "      <td>面上项目</td>\n",
       "      <td>1&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>2&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>3&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>4&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>5&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>有向图的圈划分及相关问题研究</td>\n",
       "      <td>颜谨</td>\n",
       "      <td>数学学院</td>\n",
       "      <td>面上项目</td>\n",
       "      <td>1&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>2&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>3&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>4&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>5&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>哈密顿偏微分方程的稳定性</td>\n",
       "      <td>李静</td>\n",
       "      <td>数学与统计学院</td>\n",
       "      <td>面上项目</td>\n",
       "      <td>1&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>2&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>3&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>4&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>5&gt;具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             项目名称  申请人     申请部门  资助类别  \\\n",
       "41             自守形式和自守L-函数的相关解析问题   徐钊     数学学院  面上项目   \n",
       "42              有界格上聚合与推理算子的理论与应用  刘华文     数学学院  面上项目   \n",
       "43  多凯勒参数卡拉比-丘型的纽Gromov-Witten不变量   王新     数学学院  面上项目   \n",
       "44                 有向图的圈划分及相关问题研究   颜谨     数学学院  面上项目   \n",
       "45                   哈密顿偏微分方程的稳定性   李静  数学与统计学院  面上项目   \n",
       "\n",
       "                                                  意见1  \\\n",
       "41  1>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "42  1>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "43  1>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "44  1>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "45  1>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "\n",
       "                                                  意见2  \\\n",
       "41  2>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "42  2>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "43  2>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "44  2>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "45  2>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "\n",
       "                                                  意见3  \\\n",
       "41  3>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "42  3>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "43  3>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "44  3>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "45  3>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "\n",
       "                                                  意见4  \\\n",
       "41  4>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "42  4>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "43  4>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "44  4>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "45  4>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   \n",
       "\n",
       "                                                  意见5  立项  \n",
       "41  5>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   0  \n",
       "42  5>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   1  \n",
       "43  5>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   0  \n",
       "44  5>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   1  \n",
       "45  5>具体评价意见：\\n一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理...   1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['意见6'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-57ad29953e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_json_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_app\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"申请人\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见6\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"立项\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_json_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_json_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_json_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"意见6\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"立项\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_json_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwide_to_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'意见'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'评审'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['意见6'] not in index\""
     ]
    }
   ],
   "source": [
    "df_json_full = df_app[[\"申请人\",\"意见1\",\"意见2\",\"意见3\",\"意见4\",\"意见5\",\"立项\"]]\n",
    "df_json_full['id'] = df_json_full.index\n",
    "df_json = df_json_full[['id',\"意见1\",\"意见2\",\"意见3\",\"意见4\",\"意见5\",\"立项\"]]\n",
    "\n",
    "df_json_long = pd.wide_to_long(df_json, stubnames='意见', i=['id'], j='评审')\n",
    "df_json_long.reset_index(inplace=True)\n",
    "df_json_long.rename(columns={\"立项\":\"records\",\"意见\":\"content\"},inplace=True)\n",
    "df_json_long.dropna(inplace=True)\n",
    "df_json_long.sort_values(['id'])\n",
    "df_json_long[\"records\"].replace(to_replace=0, value=\"负\",inplace=True)\n",
    "df_json_long[\"records\"].replace(to_replace=1, value=\"正\",inplace=True)\n",
    "df_json_long = df_json_long[[\"id\",\"records\",\"content\"]]\n",
    "\n",
    "\n",
    "#sample_size = 5000\n",
    "sample_size = df_json_long.shape[0]\n",
    "\n",
    "df_json_sample = df_json_long.iloc[0:sample_size,:]\n",
    "result = df_json_sample.to_json(orient=\"index\",force_ascii=False)\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(result,f,ensure_ascii=False)\n",
    "    \n",
    "df_json_sample.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理步骤\n",
    "1. 去除重复词语\n",
    "2. 去除stop words\n",
    "3. 分词\n",
    "4. 生成embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重复词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pat(line):\n",
    "    pat = ['一、该申请项目所关注的科学问题是否源于多学科领域交叉的共性问题，具有明确的学科交叉特征？请详细阐述判断理由并评价预期成果的科学价值。',\n",
    "          '二、请针对学科交叉特点评述申请项目研究方案或技术路线的创新性和可行性。',\n",
    "          '三、请评述申请人的多学科背景、研究专长和创新潜力。',\n",
    "          '四、其他建议',\n",
    "          '1>',\n",
    "          '（1）',\n",
    "          '（2）',\n",
    "          '（3）',\n",
    "          '（4）',\n",
    "          '（5）',\n",
    "           '具体评价意见：',\n",
    "          '一、该申请项目的研究思想或方案是否具有新颖性和独特性？请详细阐述判断理由。',\n",
    "          '二、请评述申请项目所关注问题的科学价值以及对相关前沿领域的潜在贡献。',\n",
    "          '三、请评述申请人的创新潜力与研究方案的可行性',\n",
    "          '一、该申请项目是否面向国家需求并试图解决技术瓶颈背后的基础问题？请结合应用需求详细阐述判断理由。',\n",
    "          '二、请评述申请项目所提出的科学问题与预期成果的科学价值。',\n",
    "          '三、请评述申请人的创新潜力及研究方案的创新性和可行性。',\n",
    "          '。',\n",
    "          '，',\n",
    "          '、',\n",
    "          '的',\n",
    "          '研究',\n",
    "          '三请',\n",
    "          '申请人',\n",
    "          '拟']\n",
    "\n",
    "    line = re.sub(\"\\n\", \"\", line)\n",
    "    for x in pat:\n",
    "        line = re.sub(x, \"\", line)\n",
    "    \n",
    "    # stopwords\n",
    "    stopwords=pd.read_csv('stopwords.txt', header=None)[0].tolist() \n",
    "    for x in stopwords:\n",
    "        line = re.sub(x, \"\", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sample[\"content_clean\"] = df_json_sample[\"content\"].apply(clean_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sample[\"content_clean\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用机器学习模型预测评审意见的正负"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们定义一个文档集合存储于List，每个文档为list的一个元素，每个文档都对应一个标签,存储于labels\n",
    "seg_lists = list()\n",
    "lines = list(df_json_sample['content_clean'])\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    #seg_list = list(seg_list)\n",
    "    seg_lists.append(jieba.cut(line))\n",
    "    #print(len(seg_list))\n",
    "sentences = []\n",
    "for i in seg_lists:      \n",
    "    sentences.append(' '.join(i))    \n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_json_sample[\"records\"]\n",
    "labels.replace(\"负\",0,inplace=True)\n",
    "labels.replace(\"正\",1,inplace=True)\n",
    "labels = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ''.join(map(str, sentences))\n",
    "# = re.sub(\"\\n\", \"\", line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(font_path = '/System/Library/Fonts/STHeiti Light.ttc',\n",
    "            background_color=\"white\",# 设置背景颜色\n",
    "           max_words=80, # 词云显示的最大词数\n",
    "           height=400, # 图片高度\n",
    "           width=800, # 图片宽度\n",
    "           max_font_size=50).generate(texts)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "# The pil way (if you don't have matplotlib)\n",
    "# image = wordcloud.to_image()\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 14000 #估计的词汇表大小，设置时要比真实的词汇量大，不然会产生不同单词分配了相同的索引。\n",
    "\n",
    "# #通过索引对上面句子进行编码，one_hot编码映射到[1,vocab_size]，不包括0\n",
    "# encoded_docs = [one_hot(s, vocab_size) for s in sentences]\n",
    "# # 文本编码成数字格式并padding到相同长度，这里长度设置为4，在后面补0，这也是为什么前面one-hot不会映射到0的原因。\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "encoded_docs = tokenizer.texts_to_sequences(sentences)\n",
    "max_length = 200\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(padded_docs,labels, test_size=0.2)\n",
    "train_size = 2000\n",
    "X_train  = padded_docs[0:train_size,:]\n",
    "X_val  = padded_docs[train_size:,:]\n",
    "y_train  = labels[0:train_size]\n",
    "y_val    = labels[train_size:]\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 20, input_length=max_length))  # Embedding layer\n",
    "model.add(Bidirectional(LSTM(15)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid',kernel_regularizer='l2'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                     optimizer='adam', \n",
    "                     metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_train = []\n",
    "for i in X_train:\n",
    "    input = np.expand_dims(i,axis=0)\n",
    "    senti_train.append(model.predict(input))\n",
    "\n",
    "senti_train_num = []\n",
    "for i in range(len(senti_train)):\n",
    "    senti_train_num.append(senti_train[i][0][0])\n",
    "\n",
    "senti_train = pd.DataFrame(list(zip(senti_train_num, y_train)), columns =['Senti', 'Y'])\n",
    "senti_train.groupby('Y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_train.loc[senti_train['Y']==0,'Senti'].plot.density()\n",
    "senti_train.loc[senti_train['Y']==1,'Senti'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_val = []\n",
    "for i in X_val:\n",
    "    input = np.expand_dims(i,axis=0)\n",
    "    senti_val.append(model.predict(input))\n",
    "    \n",
    "senti_val_num = []\n",
    "for i in range(len(senti_val)):\n",
    "    senti_val_num.append(senti_val[i][0][0])\n",
    "\n",
    "senti_val = pd.DataFrame(list(zip(senti_val_num, y_val)), columns =['Senti', 'Y'])\n",
    "senti_val.groupby('Y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_val.loc[senti_val['Y']==0,'Senti'].plot.density()\n",
    "senti_val.loc[senti_val['Y']==1,'Senti'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the sentiment back to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = senti_train.append(senti_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_id = df_json_sample.join(senti)[['id','Senti']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_id.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_id.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_id_avg = senti_id.groupby('id')['Senti'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_json_full.merge(senti_id_avg, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby('立项')['Senti'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['立项']==0,'Senti'].plot.density()\n",
    "df_final.loc[df_final['立项']==1,'Senti'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_negative = (df_final['立项']==0) & (df_final['Senti']>=0.2) & (df_final['Senti']<=0.6)\n",
    "df_rd_neg = df_final[rd_negative]\n",
    "rd_positive = (df_final['立项']==1) & (df_final['Senti']>=0.2) & (df_final['Senti']<=0.6)\n",
    "df_rd_positive = df_final[rd_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd_neg['申请人']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd_positive.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
